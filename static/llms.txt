# SkillGuard: SSL for Agent Skills
> First line of defense for AI agent skill safety — with verifiable zero-knowledge ML proofs

## What this API does
SkillGuard is a fast, cheap safety check for AI agent skills. It classifies skills as
SAFE, CAUTION, or DANGEROUS with a two-layer defense: MLP classifier (91.3% DANGEROUS recall, 95.9% i32 holdout) plus a deterministic rule-based danger floor (7 rules) and safe floor (1 rule) that catch pattern-matched threats and prevent false positives.
Every classification includes a mandatory cryptographic zkML proof (SNARK via Jolt/Dory)
that anyone can verify independently. Think of it as an SSL certificate for agent skills:
the proof guarantees the classification was computed correctly by the neural network.

SkillGuard is a first line of defense, not a complete security solution. Pair it with
sandboxing, human review for flagged skills, and runtime monitoring.

## Base URL
https://skillguard.onrender.com

## Authentication
- x402 payment: $0.001 USDC on Base per classification (no API key needed)
- Or: Bearer token via Authorization header

## Endpoints

### Classify a skill (paid)
POST /api/v1/evaluate
Content-Type: application/json

By name (looks up skill on ClawHub):
{"skill": "skill-slug-name"}

With full data:
{"skill": {"name": "my-skill", "version": "1.0.0", "author": "alice", "description": "A skill", "skill_md": "# My Skill\nDoes something useful.", "scripts": [], "files": []}}

Response includes: classification, is_dangerous (boolean), decision, confidence, class scores, reasoning, and a zkML proof bundle. Agents that just need a binary safe/not-safe answer can check the is_dangerous field directly.

### Verify a proof (free, no auth)
POST /api/v1/verify
Content-Type: application/json
{"proof_b64": "...", "program_io": {...}}

Returns: {"valid": true, "verification_time_ms": 74}

### Catalog lookup (free, no auth, instant)
GET /api/v1/catalog/{skill_name}

Returns cached classification data for a previously evaluated skill without re-running
the model or generating a new proof. Instant response, no authentication required.

Example: GET /api/v1/catalog/4claw
Returns: {"success": true, "entry": {"skill_name": "4claw", "classification": "SAFE", "decision": "ALLOW", "confidence": 0.97, "scores": {...}, "model_version": "...", "evaluated_at": "..."}}

Returns 404 if the skill has not been evaluated before.

### Health check (free)
GET /health

### Usage statistics (free)
GET /stats

### OpenAPI spec
GET /openapi.json

### Agent discovery manifest
GET /.well-known/ai-plugin.json

## Pricing
$0.001 USDC per classification on Base (EIP-155 chain 8453).
Payment via x402 protocol (HTTP 402 flow with ERC-3009 TransferWithAuthorization).
Verification is always free.

## Example: one-shot classify
curl -X POST https://skillguard.onrender.com/api/v1/evaluate \
  -H "Content-Type: application/json" \
  -d '{"skill": "4claw"}'

## Model (v2.3, v3.0 training pipeline in progress)
3-layer MLP: 45 inputs → 56 hidden (ReLU) → 40 hidden (ReLU) → 3 outputs.
4,979 parameters. Fixed-point i32 arithmetic (scale=7, rounding division).
QAT-trained with exact i32 integer-division simulation + FGSM adversarial examples.
Softmax temperature T=0.95 on integer-scale logits (ECE=0.045).
~53 KB proofs, ~4s proving time.

Safety metrics (what matters for a first line of defense):
  DANGEROUS catch rate (MLP): 91.3% + deterministic danger floor for pattern-matched threats
  DANGEROUS recall (i32 holdout): 95.9%
  Binary DANGEROUS-vs-rest accuracy: 84.7%
  Binary DANGEROUS-vs-rest metrics available in /health and /stats responses.

v2.3 (current): 619 LLM-labeled real OpenClaw skills + augmented samples.
  Three-layer defense: MLP classifier + 7 danger-floor rules + 1 safe-floor rule.
  MLP metrics: DANGEROUS recall: 91.3%, F1: 0.76. CAUTION recall: 57.2%, F1: 0.61. SAFE F1: 0.52.
  3-class accuracy: 63.0%. Danger floor catches reverse shells, data exfiltration,
  credential harvesting, curl|bash, privilege escalation, and LLM secret exposure deterministically.
  Safe floor prevents false positives on trivially benign skills (all risk features zero).
  is_dangerous boolean in evaluate response for binary safe/not-safe answers.
  BinarySafetyMetrics (catch rate, miss rate, accuracy) in /health and /stats.
v3.0 (target): 1,400+ real skills with improved labeling, 15% held-out test set.
  Target: ≥95% DANGEROUS catch rate, ≥80% 3-class accuracy.

Training improvements applied in v2.3:
1. Danger-sensitive loss (weight=20) — penalizes DANGEROUS false negatives 20x
2. DANGEROUS-priority checkpoint selection — safety metric weights: SAFE=0.15, CAUTION=0.30, DANGEROUS=0.55
3. Improved hard negative mining — 4x DANGEROUS replication, suppressed CAUTION mining in danger-priority mode
4. Aggressive SMOTE oversampling (0.28 target ratio) + 35 synthetic DANGEROUS augmentations
5. Stronger adversarial training (epsilon=1.0) with lower focal-gamma (1.0)
6. Safe floor rule — downgrade DANGEROUS to CAUTION when all 12 risk features are zero
7. Three-layer defense: MLP + danger floor (7 rules) + safe floor (1 rule)

The model extracts 45 numeric features from each skill (shell exec counts, network calls,
obfuscation score, reverse shell patterns, credential access, author reputation, download
counts, byte entropy, density ratios, interaction terms, cross-features like credential+exfil
co-occurrence, stealth composite, undocumented risk). When a skill has no separate scripts,
code blocks inside SKILL.md are extracted and analyzed. Features are scaled to 0-128 and fed
through the network. The highest of the 3 output scores (SAFE, CAUTION, DANGEROUS) determines
the classification, then a deterministic safety floor checks for unambiguous threat patterns
(reverse shells, data exfiltration, credential harvesting, curl|bash) and overrides to
DANGEROUS if any are detected. Confidence is the softmax probability of the top class.
High-entropy (uncertain, >0.67 normalized) predictions are flagged for review.

## Model versioning
Every evaluation response includes a model_version field containing the SHA-256 hash
of the model bytecode used for that classification. Catalog entries also include the
model_version so you can tell whether a cached result was produced by the current model
or an older one. Check /health for the active model_hash.

## Links
- OpenAPI spec: https://skillguard.onrender.com/openapi.json
- Agent plugin manifest: https://skillguard.onrender.com/.well-known/ai-plugin.json
- GitHub: https://github.com/hshadab/skillguard
- x402 protocol: https://www.x402.org/
